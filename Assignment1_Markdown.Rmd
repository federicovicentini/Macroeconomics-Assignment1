---
title: "Macroeconomics - Assignment no.1"
author: "Federico Vicentini , Riccardo Dal Cero, Xhesjana Shametaj, Alice Pratesi"
date: "27/5/2022"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Initial Operations

```{r p0, message=FALSE}

# Clear the variables
rm(list = ls())

# Set the working directory to source file location with
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Install packages
packages <- c("tidyverse", "rsdmx", "eurostat", "tbl2xts", 
              "tidyquant", "BCDating", "pwt10", "dplyr",
              "stargazer", "car")
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))

# Load packages
library(quantmod)
library(eurostat)

```

## POINT 1

First of all, we need to download the USA data from the Fred database, using a for cycle and the function $\texttt{getSymbols()}$

```{r p1}

nipa <- c("EXPGS", "IMPGS", "PCEC", "GDP", "GPDI", "GCE")
for (i in 1:length(nipa)) {
  getSymbols(nipa[i], src = "FRED")
}

```

After that we get residuals from NIPA equation (using function $\texttt{res}$) to prove that y = sum of its components. Finally, we plot them
```{r p1.2}
res=((EXPGS - IMPGS + PCEC + GPDI + GCE) - GDP)^2
plot(res)
```

We can see from the plot that residuals are overall pretty close to zero, thus probably they come from rounding errors. We conclude that the identity is checked.


Now we check the same identity for other two countries from the Eurostat Database (we chose Spain and France). 
Firstly we get Eurostat data listing
```{r p1.3}
toc <- get_eurostat_toc()
```

Then we load some other packages
```{r p1.4}
library(knitr)
library(xts)
library(ecb)
```


```{r p1.4.1, message = FALSE, include=FALSE}
# For the original data, see
# http://ec.europa.eu/eurostat/tgm/table.do?tab=table&init=1&plugin=1&language=en&pcode=tsdtr210
```

Secondly, we import GDP data from Eurostat 
```{r p1.5, message=FALSE}
namq_10_gdp <- get_eurostat("namq_10_gdp",
  stringsAsFactors = FALSE)
```


Subsequently we create new vectors. The first one is filled with the list of the two countries selected, the second with codes for NIMA aggregates (GDP, Investment, Consumption, Import, Export, Public Spending) 
```{r p1.6}

nimacountries <- c("ES", "FR")

nimaeu <- c("B1GQ", "P31_S14_S15", "P3_S13", "P51G", "P52", "P53", "P6", "P7")

```

Obviously we need to create a matrix dataeu to fill with data from the two countries.

```{r p1.7}

colname <- c( "GDP", "C", "G", "I", "inv", "saldo", "X", "IM",
  "GDPb", "Cb", "Gb", "Ib", "invb", "saldob", "Xb", "IMb")

dataeu <- matrix(NA, 89, length(nimacountries) * length(nimaeu))
colnames(dataeu) <- colname
```

Finally, we design a "for" cycle to fill dataeu with data from the two countries and we filter for our variables of interest in the period going from 2000 onward.
```{r p1.8}
z <- length(colname) / length(nimacountries)
for (i in 1:length(nimacountries)) {
  for (s in 1:length(nimaeu)) {
    newdata <- namq_10_gdp %>%
      filter(geo == nimacountries[i]) %>%
      filter(time >= "2000-01-01") %>%
      filter(unit == "CP_MEUR") %>%
      filter(s_adj == "SCA") %>%
      filter(na_item == nimaeu[s])
    newdata$time <- convert_dates(newdata$time)
    newdataxts <- xts(newdata$values, newdata$time)
    dataeu[, (s + (z * (i - 1)))] <- newdataxts
  }
}
```

Before we check the NIMA identity for both countries, we first change Imports from positive to negative to simplify the equation and we convert dataeu to xts format

```{r p1.8.1}
dataeu[, z] <- dataeu[, z] * (-1)
dataeu[, length(colname)] <- dataeu[, length(colname)] * (-1)

dataeu <- xts(dataeu, rev(newdata$time))
```

Now we check the NIMA identity for Country 1 (Spain) in this way:
- we create an empty vector to fill with the sums of the macro aggregates and another one to fill with GDP
- We fill them with the data using a for cycle 
- We print the value and plot the graphs of SUM and GDP

```{r p1.9}

sums <- c()
gdp <- c()

for (i in 1:nrow(dataeu)) {
  sums[i] <- sum(dataeu[i, -c(1, (z + 1):length(colname))])
  gdp[i] <- dataeu[i, 1]
}

plot(sums, col = "green", type = "l")
lines(gdp, col = "red", type = "b")
plot(sums - gdp)
```

We can see from the first graph the two lines are overlapping, so the identity is checked. Furthermore, even when plotting residuals we see that they are exactly zero.

To check the identity for the second country (France), the code is the same
```{r p1.20}
sums2 <- c()
gdp2 <- c()
for (i in 1:nrow(dataeu)) {
  sums2[i] <- sum(dataeu[i, -c(1:(z + 1))])
  gdp2[i] <- dataeu[i, (z + 1)]
}

plot(sums2, col = "green", type = "l")
lines(gdp2, col = "red", type = "b")
plot(sums2 - gdp2)
```

Here the only difference is that the overlap is not perfect, but residuals are nonetheless pretty close to zero. Thus, the identity is checked even for Country 2.

## POINT 2

First of all, we import the library BCDating and we generate a matrix to fill with the log of the variables. We decided to take the log level to transform data, as the paper suggested.

```{r p2}
library(BCDating)

data_bc <- matrix(NA, length(GDP), 4)

data_bc[, 1] <- log(GDP)
data_bc[, 2] <- log(IMPGS)
data_bc[, 3] <- log(GPDI)
data_bc[, 4] <- log(PCEC)
```

After that, we create a quarterly time series with a for cycle.

```{r p2.1}
for (count in 1:4) {
  data_ts <- ts(data_bc[, count], start = c(1947, 1), frequency = 4)

# Then we apply the BBQ methods (Bayesian Binning into Quantiles)  to obtain a well-calibrated confidence estimate and we plot the results 
  bc_US <- BBQ(data_ts, name = count)
  summary(bc_US)
  plot(bc_US, data_ts)
}

```

Let's analyze our results one by one:

-The first variable (GDP) presents long phases of expansion coupled with shorter periods of recession. According to our results, we are now in a period of expansion which has strated pretty recently, thus we do not expect a recession to hit soon.

-The second variable (Imports) presents long phases of expansion coupled with shorter periods of recession. According to our results, we are now in a period of expansion which has strated pretty recently, thus we do not expect a recession to hit soon.


As you can see, for the first variable (GDP) we have long phases of Expansion (ex.202) and nowadays we are in a phase of Expansion.
For the Imports we can see more phases and at the end of the 2020 started a new Expansion 
Fort the Investment (GDPI) there are a lot oh phases (41) and we can see that the longer Expansions are between 1960-1966 and between 2009-2015.
At the end for the Consumption, we can see that between 2009 and 2019 there was a very long phase of Expansion 

To sum up 


## POINT 4

First of all, we need to download the aggregate data from the website of the book "Applied Macroeconomics" by Favero and we delete the ID column since it is unuseless for our purpose
```{r p4.1}
favero <- read.csv("MRW.csv", sep = ";", dec = ",")

favero$ID <- NULL
```

Now we can create a dataframe with only the variables we are interested in: YL85 that is the GDP per working age person il 1985, N6085 that is the rate of growth of population and IY that is investment on GDP (we also change the name)
```{r p4.2}
replica <- data.frame(favero$YL85, favero$N6085, favero$IY)
names(replica) <- c("Ypc", "PopGrowth", "IonY")
```

To replicate the results of Favero, we need to transform our variables into logarithms and we add g+delta (=005) to n.
Since the equation is: log(Y/L) = a + (alfa/1+alfa)*ln(s) - (alfa/1-alfa)*ln(n+g+delta)
Where "s" is the average share of real investment, "Y/L" is the real GDP and "delta" is the rate of depreciation 
```{r p4.3}
replica$Ypc <- log(replica$Ypc)
replica$PopGrowth <- log(((replica$PopGrowth) / 100) + 0.05)
replica$IonY <- log((replica$IonY) / 100)
names(replica)[2] <- "ngdelta"
```

Finally, we can compute our simple regression that is to replicate the regression results and print them using stargazer function
```{r p4.4}
reg <- lm(Ypc ~ IonY + ngdelta, data = replica)

library(stargazer)
stargazer(reg, type = "text")
```

As we can see from the text, the constant correspond to 5.36 (equal to the book), IonY that is Investement on GDP corrrspond to 1.32 that is equal to the value of the book and at the end ngdelta (00.5 + n) is  -2.01 that corresponf to the value of the table of the book.


Now we can do hyphothesis testing with the two provided restrictions: 
1. Beta1 = - Beta2
2. Beta1 = 0.5 and Beta2 = -0.5
```{r p4.5}
library(car)
linearHypothesis(reg, c("IonY-ngdelta=0"), test = "F")
linearHypothesis(reg, c("IonY=0.5", "ngdelta=-0.5"), test = "F")

```
To sum up we can say that the results of our study are coherent with the results of the regression, infact th the results of the coefficients are equal to 0.5 i risultati dello studio sono coerenti con i risultati della regressione con 
The second test the value of the two Beta's

At the end to provide a measure of uncertainty in parameters we use the Boot function from the package car
```{r p4.6}
Boot(reg)

library(boot)
```

But to implement the function Boot we need to create a Bootstrap function to get coefficients from the regression
```{r p4.7}
bs = function(formula, data, indices){
  d = data[indices,]
  fit=lm(formula, data=d)
  return(coef(fit))
}

```

#Create var results with function boot on the regression

results = boot(replica, statistic=bs, R=1000, formula= Ypc ~ IonY + ngdelta)

#Print the results

results



#Add schooling the replica database

replica$school=log((favero$SCHOOL)/100)



#Replicate the augmented Solow model

reg2 = lm(Ypc ~ IonY + ngdelta + school, data = replica)

#Print results using the Stargazer function

stargazer(reg2, type = "text")


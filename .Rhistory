summary(ridge_0)
ridge_0$beta    # the ridge estimated coefficientes, beta1, beta2 estimates ... beta_p
# They are the OLS estimates coefficientes
ridge_0$a0 #beta_0
# we want to run ridge regression with lambda > 0
# since we do not know how to choose it, we run ridge for a grid of values of lambda
grid = 10^seq(-2, 10, length = 100)
grid
plot(grid)
grid[1]
grid[2]
grid[100]
ridge_grid = glmnet(X,y, alpha = 0, lambda = grid, standardize = TRUE)
# I implement ridge regression 100 times, each time with different value of lambda in grid
# See the coefficient estimates of ridge_grid
coef_grid = coef(ridge_grid)
coef_grid   # 19 parameters row of matrix and 100 columns for each value of lambda
# I want to select the 100 coefficient estimates associated with predictors Hits (the second row)
coef_grid[2,] # these is the collection of estimates for beta_1 as a function of lambda
# PAY ATTENTION! Results are sorted by decreasing values of lambda
# Let me sort these estimates for increasing values of lambda
100:1
beta_2_ridge = coef_grid[3,100:1]  # now sorted by increasing values of lambda, e.g. lambda --> infinity
beta_2_ridge
plot(beta_2_ridge, type = "l", xlab = expression(lambda), ylab = expression(beta[2]))
# ridge estimates of beta_1 if you increase lambda Beta_1 is zero
# How to choose lambda??
## Use cross validation to choose lambda
## In what follows I adopt k-fold cross validation to chose among models
## This is implemented in function cv.glmnet
set.seed(1)
cv_out = cv.glmnet(X, y, lambda = grid, alpha = 0) #alpha = 0 for ridge regression
cv_out
plot(cv_out)
# each point is the cross validation error for one of the model, for each value of lambda
# if i want to select a model based on the mean square error, I chose the model with the smallest mean square error
# star decrease mean square error but then surprising start increasing (too high)
# at some point the ridge regresion is shrinking the value of beta = 0 remove coefficient = 0, loss accurancy in model
# I would chose with lambda = 5 similar minimum one
# 18 18 18 18 stands for number of predictors include in each model, not variable selection
plot(cv_out)
cv_out$lambda
cv_out$lambda.min # i choose with the minimum lambda
lmbda_hat = cv_out$lambda.min # i choose with the minimum lambda
cv_out = glmnet(X, y, lambda = lambda_hat, alpha = 0)
lmbda_hat = cv_out$lambda.min # i choose with the minimum lambda
lambda_hat
lambda_hat = cv_out$lambda.min # i choose with the minimum lambda
lambda_hat
cv_out = glmnet(X, y, lambda = lambda_hat, alpha = 0)
cv_out.opt$beta
round(cv_out.opt$beta,2)
round(cv_out_opt$beta,2)
round(cv_out_opt$beta,2)
cv_out.opt$beta
cv_out_opt$beta
cv.out.opt$beta
grid
glmnet(X, y, lambda = grid, alpha = 1)
lasso_grid = glmnet(X, y, lambda = grid, alpha = 1) # implement LASSO regression
coef(lasso_grid)
plot(lasso_grid)
coef_grid = coef(lasso_grid)
beta_1_ridge = coef_grid[2,100:1]
plot(beta_1_ridge, type = "l")
beta_2_ridge = coef_grid[3,100:1]
plot(beta_2_ridge, type = "l")
plot(beta_1_ridge, type = "l") # beta_1 = around 2 then decrease at some value of lambda the coeff is = 0 exactly
lasso_grid = cv.glmnet(X, y, lambda = grid, alpha = 1)
plot(lasso_grid)
lambda_hat = lasso_grid$lambda.min
lambda_hat
lasso_hat = cv.glmnet(X, y, lambda = lambda_hat, alpha = 1)
lasso_hat = glmnet(X, y, lambda = lambda_hat, alpha = 1)
lasso_hat$beta
#Federico Vicentini
#23/05/2022
#Macroeconomics - Assignment no.1
#################
#####POINT 1#####
#################
#Clear the variables
rm(list=ls())
#Set the working directory to source file location with
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#Load packages
library(quantmod)
library(eurostat)
#Get Data from Fred website
nipa=c("EXPGS","IMPGS","PCEC","GDP","GPDI","GCE")
for (i in 1:length(nipa)) {
getSymbols(nipa[i],src='FRED')
}
#Plot residuals from NIPA equation
((EXPGS-IMPGS+PCEC+GPDI+GCE)-GDP)^2
plot(((EXPGS-IMPGS+PCEC+GPDI+GCE)-GDP)^2)
# GET THE OTHER TWO COUNTRIES FROM EUROSTAT DATABASE
# Install packages
packages <- c("tidyverse","rsdmx","eurostat","tbl2xts","tidyquant","BCDating","pwt10","dplyr")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))
# Get Eurostat data listing
toc <- get_eurostat_toc()
# Check the first items
library(knitr)
kable(tail(toc))
library(xts)
library(ecb)
# For the original data, see
# http://ec.europa.eu/eurostat/tgm/table.do?tab=table&init=1&plugin=1&language=en&pcode=tsdtr210
# GDP download
namq_10_gdp <- get_eurostat("namq_10_gdp",
stringsAsFactors = FALSE)
# Create vector with list of countries
nimacountries=c("ES","FR")
# Create a vector with codes for NIMA aggregates
nimaeu=c("B1GQ","P31_S14_S15","P3_S13","P51G","P52","P53","P6","P7")
# Create a vector with names for columns in matrix dataeu
colname=c("GDP","C","G","I","inv","saldo","X","IM",
"GDPb","Cb","Gb","Ib","invb","saldob","Xb","IMb")
# Create matrix dataeu to fill with data from the 2 countries
dataeu=matrix(NA,89,length(nimacountries)*length(nimaeu))
colnames(dataeu)=colname
# Set z to partition columns
z=length(colname)/length(nimacountries)
# For cycle to fill dataeu with data from the countries
for (i in 1:length(nimacountries)) {
for (s in 1:length(nimaeu)) {
newdata<-namq_10_gdp %>%
filter(geo == nimacountries[i]) %>%
filter(time >= '2000-01-01') %>%
filter(unit == 'CP_MEUR') %>%
filter(s_adj == 'SCA') %>%
filter(na_item == nimaeu[s])
newdata$time<-convert_dates(newdata$time)
newdataxts<-xts(newdata$values,newdata$time)
dataeu[,(s+(z*(i-1)))]=newdataxts
}
}
#Change Imports from positive to negative in both countries
dataeu[,z]=dataeu[,z]*(-1)
dataeu[,length(colname)]=dataeu[,length(colname)]*(-1)
#Convert dataeu to xts format
dataeu<-xts(dataeu,rev(newdata$time))
#Check NIMA identity for country 1
sums=c()
gdp=c()
for (i in 1:nrow(dataeu)) {
sums[i]=sum(dataeu[i,-c(1,(z+1):length(colname))])
gdp[i]=dataeu[i,1]
}
sum(dataeu[i,-c(1,z:length(colname))])-dataeu[i,z]
dataeu[,-c(1,z:length(colname))]
plot(sums, col="green", type="l")
lines(gdp, col="red", type="l")
plot(sums-gdp)
#Check NIMA identity for country 2
sums2=c()
gdp2=c()
for (i in 1:nrow(dataeu)) {
sums2[i]=sum(dataeu[i,-c(1:(z+1))])
gdp2[i]=dataeu[i,(z+1)]
}
sum(dataeu[1,-c(1:(z+1))])-dataeu[1,length(colname)]
dataeu[i,(z+1)]
dataeu[1,-c(1:(z+1),length(colname))]
plot(sums2, col="green", type="l")
lines(gdp2, col="red", type="l")
plot(sums2-gdp2)
plot(sums-gdp) #plot the residual to check if Y=C+G+I
#################
#####POINT 2#####
#################
library(BCDating) #import
data_bc<-matrix(NA,length(GDP),4) #generate a matrix to fill with the log of the variables
#taking logs
data_bc[,1]<-log(GDP)
data_bc[,2]<-log(IMPGS)
data_bc[,3]<-log(GPDI)
data_bc[,4]<-log(PCEC)
for (count in 1:4) {
#create a time series with the variable[count]
#setting the time index as year-quarter
data_ts<-ts(data_bc[,count],start = c(1947, 1), frequency = 4)
#applied the BBQ method
bc_US<-BBQ(data_ts,name= count)
#plot the results
summary(bc_US)
plot(bc_US,data_ts)
}
#################
#####POINT 3#####
#################
rm(list = ls())
library(pwt10)
library(dplyr)
data("pwt10.0")
penn=pwt10.0
rm(pwt10.0)
list=c("1950","1960","1970","1980","1990","2000","2010")
uspenn<-penn %>%
filter(country == "United States of America")
uslabsh=uspenn %>%
select(c(year,labsh))
espenn<-penn %>%
filter(country == "Spain")
eslabsh=espenn %>%
select(c(year,labsh))
frpenn<-penn %>%
filter(country == "France")
frlabsh=frpenn %>%
select(c(year,labsh))
usfilt=uslabsh %>%
filter(year %in% list)
plot(usfilt$year,usfilt$labsh, ylim=c(0,1),
type="b",
ylab="Labour Share of Total Income",
xlab="Year", main="US")
esfilt=eslabsh %>%
filter(year %in% list)
plot(usfilt$year,esfilt$labsh, ylim=c(0,1),
type="b",
ylab="Labour Share of Total Income",
xlab="Year", main="SPAIN")
frfilt=frlabsh %>%
filter(year %in% list)
plot(frfilt$year,frfilt$labsh, ylim=c(0,1),
type="b",
ylab="Labour Share of Total Income",
xlab="Year", main="FRANCE")
table_10 <- matrix(NA, ncol = 6, nrow = 10)
countries <- c("United States of America", "France", "Germany", "Japan",
"Canada", "China", "Russian Federation", "Ukraine", "Netherlands", "United Kingdom")
char <- c("country", "rgdpna", "rtfpna", "rnna", "avh", "emp")
table_10[,1] <- countries
colnames(table_10) <- char
penn_years <- penn %>%
filter((year >= 1959) & (year <= 2000) & (country %in% countries ))
filter(penn, (country %in% countries )
#################
#####POINT 4#####
#################
favero=read.csv("MRW.csv",sep=";",dec = ",")
favero$ID=NULL
replica=data.frame(favero$YL85,favero$N6085,favero$IY)
names(replica)=c("Ypc","PopGrowth","IonY")
replica$Ypc=log(replica$Ypc)
replica$PopGrowth=log(((replica$PopGrowth)/100)+0.05)
replica$IonY=log((replica$IonY)/100)
names(replica)[2]="ngdelta"
reg=lm(Ypc ~ IonY + ngdelta, data=replica)
library(stargazer)
stargazer(reg, type = "text")
t.test(lm(Ypc ~ IonY + ngdelta, data=replica))
library(car)
linearHypothesis(reg, c("IonY-ngdelta=0"),test="F")
linearHypothesis(reg, c("IonY=0.5","ngdelta=-0.5"),test="F")
## Classical example: Student's sleep data
plot(extra ~ group, data = sleep)
## Traditional interface
with(sleep, t.test(extra[group == 1], extra[group == 2]))
?toc
get_eurostat_toc()
kable(tail(toc))
?kable
z
# Clear the variables
rm(list = ls())
# Set the working directory to source file location with
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load packages
library(quantmod)
library(eurostat)
# Get Data from Fred website
nipa <- c("EXPGS", "IMPGS", "PCEC", "GDP", "GPDI", "GCE")
for (i in 1:length(nipa)) {
getSymbols(nipa[i], src = "FRED")
}
# Plot residuals from NIPA equation
((EXPGS - IMPGS + PCEC + GPDI + GCE) - GDP)^2
plot(((EXPGS - IMPGS + PCEC + GPDI + GCE) - GDP)^2)
# Install packages
packages <- c("tidyverse", "rsdmx", "eurostat", "tbl2xts",
"tidyquant", "BCDating", "pwt10", "dplyr")
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))
# Get Eurostat data listing
toc <- get_eurostat_toc()
# Check the first items
library(knitr)
kable(tail(toc))
library(xts)
library(ecb)
# GDP download
namq_10_gdp <- get_eurostat("namq_10_gdp",
stringsAsFactors = FALSE
)
# Create vector with list of countries
nimacountries <- c("ES", "FR")
# Create a vector with codes for NIMA aggregates
nimaeu <- c("B1GQ", "P31_S14_S15", "P3_S13", "P51G", "P52", "P53", "P6", "P7")
# Create a vector with names for columns in matrix dataeu
colname <- c(
"GDP", "C", "G", "I", "inv", "saldo", "X", "IM",
"GDPb", "Cb", "Gb", "Ib", "invb", "saldob", "Xb", "IMb"
)
# Create matrix dataeu to fill with data from the 2 countries
dataeu <- matrix(NA, 89, length(nimacountries) * length(nimaeu))
colnames(dataeu) <- colname
dataeu
# Create matrix dataeu to fill with data from the 2 countries
dataeu <- matrix(NA, 89, length(nimacountries) * length(nimaeu))
dataeu
# Set z to partition columns
z <- length(colname) / length(nimacountries)
# Set z to partition columns
z <- length(colname) / length(nimacountries)
z
# For cycle to fill dataeu with data from the countries
for (i in 1:length(nimacountries)) {
for (s in 1:length(nimaeu)) {
newdata <- namq_10_gdp %>%
filter(geo == nimacountries[i]) %>%
filter(time >= "2000-01-01") %>%
filter(unit == "CP_MEUR") %>%
filter(s_adj == "SCA") %>%
filter(na_item == nimaeu[s])
newdata$time <- convert_dates(newdata$time)
newdataxts <- xts(newdata$values, newdata$time)
dataeu[, (s + (z * (i - 1)))] <- newdataxts
}
}
# Change Imports from positive to negative in both countries
dataeu[, z] <- dataeu[, z] * (-1)
dataeu[, length(colname)] <- dataeu[, length(colname)] * (-1)
# Convert dataeu to xts format
dataeu <- xts(dataeu, rev(newdata$time))
#Create empty vectors for sums of aggregates and for gdp
sums <- c()
gdp <- c()
#Fill them with the data using a for cycle
for (i in 1:nrow(dataeu)) {
sums[i] <- sum(dataeu[i, -c(1, (z + 1):length(colname))])
gdp[i] <- dataeu[i, 1]
}
#Plot the values
sum(dataeu[i, -c(1, z:length(colname))]) - dataeu[i, z]
dataeu[, -c(1, z:length(colname))]
#Plot the graphs
plot(sums, col = "green", type = "l")
lines(gdp, col = "red", type = "l")
plot(sums - gdp)
sums2 <- c()
gdp2 <- c()
for (i in 1:nrow(dataeu)) {
sums2[i] <- sum(dataeu[i, -c(1:(z + 1))])
gdp2[i] <- dataeu[i, (z + 1)]
}
sum(dataeu[1, -c(1:(z + 1))]) - dataeu[1, length(colname)]
dataeu[i, (z + 1)]
dataeu[1, -c(1:(z + 1), length(colname))]
plot(sums2, col = "green", type = "l")
lines(gdp2, col = "red", type = "l")
plot(sums2 - gdp2)
?for
variable
#Create empty vectors for sums of aggregates and for gdp
sums <- c()
gdp <- c()
#Fill them with the data using a for cycle
for (i in 1:nrow(dataeu)) {
sums[i] <- sum(dataeu[i, -c(1, (z + 1):length(colname))])
gdp[i] <- dataeu[i, 1]
}
#Plot the values
sum(dataeu[i, -c(1, z:length(colname))]) - dataeu[i, z]
dataeu[, -c(1, z:length(colname))]
#Plot the graphs
plot(sums, col = "green", type = "l")
lines(gdp, col = "red", type = "l")
plot(sums - gdp)
# Clear the variables
rm(list = ls())
# Set the working directory to source file location with
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Load packages
library(quantmod)
library(eurostat)
# Get Data from Fred website
nipa <- c("EXPGS", "IMPGS", "PCEC", "GDP", "GPDI", "GCE")
for (i in 1:length(nipa)) {
getSymbols(nipa[i], src = "FRED")
}
# Plot residuals from NIPA equation
((EXPGS - IMPGS + PCEC + GPDI + GCE) - GDP)^2
plot(((EXPGS - IMPGS + PCEC + GPDI + GCE) - GDP)^2)
# Install packages
packages <- c("tidyverse", "rsdmx", "eurostat", "tbl2xts",
"tidyquant", "BCDating", "pwt10", "dplyr")
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))
# Get Eurostat data listing
toc <- get_eurostat_toc()
# Check the first items
library(knitr)
kable(tail(toc))
library(xts)
library(ecb)
# GDP download
namq_10_gdp <- get_eurostat("namq_10_gdp",
stringsAsFactors = FALSE
)
# Create vector with list of countries
nimacountries <- c("ES", "FR")
# Create a vector with codes for NIMA aggregates
nimaeu <- c("B1GQ", "P31_S14_S15", "P3_S13", "P51G", "P52", "P53", "P6", "P7")
# Create a vector with names for columns in matrix dataeu
colname <- c(
"GDP", "C", "G", "I", "inv", "saldo", "X", "IM",
"GDPb", "Cb", "Gb", "Ib", "invb", "saldob", "Xb", "IMb"
)
# Create matrix dataeu to fill with data from the 2 countries
dataeu <- matrix(NA, 89, length(nimacountries) * length(nimaeu))
colnames(dataeu) <- colname
# Set z to partition columns
z <- length(colname) / length(nimacountries)
z
# For cycle to fill dataeu with data from the countries
for (i in 1:length(nimacountries)) {
for (s in 1:length(nimaeu)) {
newdata <- namq_10_gdp %>%
filter(geo == nimacountries[i]) %>%
filter(time >= "2000-01-01") %>%
filter(unit == "CP_MEUR") %>%
filter(s_adj == "SCA") %>%
filter(na_item == nimaeu[s])
newdata$time <- convert_dates(newdata$time)
newdataxts <- xts(newdata$values, newdata$time)
dataeu[, (s + (z * (i - 1)))] <- newdataxts
}
}
# Change Imports from positive to negative in both countries
dataeu[, z] <- dataeu[, z] * (-1)
dataeu[, length(colname)] <- dataeu[, length(colname)] * (-1)
dataeu
# Convert dataeu to xts format
dataeu <- xts(dataeu, rev(newdata$time))
dataeu
#Create empty vectors for sums of aggregates and for gdp
sums <- c()
gdp <- c()
#Fill them with the data using a for cycle
for (i in 1:nrow(dataeu)) {
sums[i] <- sum(dataeu[i, -c(1, (z + 1):length(colname))])
gdp[i] <- dataeu[i, 1]
}
#Plot the values
sum(dataeu[i, -c(1, z:length(colname))]) - dataeu[i, z]
dataeu[, -c(1, z:length(colname))]
#Plot the graphs
plot(sums, col = "green", type = "l")
lines(gdp, col = "red", type = "l")
plot(sums - gdp)
sums2 <- c()
gdp2 <- c()
for (i in 1:nrow(dataeu)) {
sums2[i] <- sum(dataeu[i, -c(1:(z + 1))])
gdp2[i] <- dataeu[i, (z + 1)]
}
sum(dataeu[1, -c(1:(z + 1))]) - dataeu[1, length(colname)]
dataeu[i, (z + 1)]
dataeu[1, -c(1:(z + 1), length(colname))]
plot(sums2, col = "green", type = "l")
lines(gdp2, col = "red", type = "l")
sums2 <- c()
sums2
gdp2
newdata$time <- convert_dates(newdata$time)
?convert_dates
#Import the library
library(BCDating)
# Generate a matrix to fill with the log of the variables
data_bc <- matrix(NA, length(GDP), 4)
data_bc
# Yaking logs
data_bc[, 1] <- log(GDP)
data_bc[, 2] <- log(IMPGS)
data_bc[, 3] <- log(GPDI)
data_bc[, 4] <- log(PCEC)
data_bc[, 1]
data_bc[, 2]
for (count in 1:4) {
# create a time series with the variable[count]
# setting the time index as year-quarter
data_ts <- ts(data_bc[, count], start = c(1947, 1), frequency = 4)
# applied the BBQ method
bc_US <- BBQ(data_ts, name = count)
# plot the results
summary(bc_US)
plot(bc_US, data_ts)
}
# create a time series with the variable[count]
# setting the time index as year-quarter
data_ts <- ts(data_bc[, count], start = c(1947, 1), frequency = 4)
# applied the BBQ method
bc_US <- BBQ(data_ts, name = count)
# plot the results
summary(bc_US)
plot(bc_US, data_ts)
